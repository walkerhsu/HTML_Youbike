{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce96f2fa-1280-4e95-b549-1dd2cdd63df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install scikit-learn \n",
    "# ! pip install numpy\n",
    "# ! pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dc887209-0332-46d2-a7e3-356c726860fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import math\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn import set_config \n",
    "\n",
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39dabeb1-8bd1-438d-be92-45d76a867fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessData(singleData):\n",
    "    singleData[5] -= 24.5\n",
    "    singleData[6] -= 121\n",
    "    if singleData[3] == 0:\n",
    "        singleData[3] = 24\n",
    "    if singleData[4] == 0:\n",
    "        singleData[4] = 60\n",
    "    singleData[4] /= 60\n",
    "    # singleData[7] = min(singleData[7], singleData[8])\n",
    "    # singleData.pop(8)\n",
    "    \n",
    "    return singleData\n",
    "\n",
    "def readDataset(data_filepath, inference_filepath):\n",
    "    assert os.path.exists(data_filepath)\n",
    "    filenames = os.listdir(data_filepath)\n",
    "    if '.DS_Store' in filenames:\n",
    "        filenames.remove('.DS_Store')\n",
    "    filenames = sorted(filenames)\n",
    "    dataset = []\n",
    "    for idx, filename in enumerate(filenames):\n",
    "        data = (pd.read_csv(data_filepath + filename).values).tolist()\n",
    "        for single_data in data:\n",
    "            single_data = preprocessData(single_data)\n",
    "            dataset.append(single_data)\n",
    "\n",
    "    testDataset = []\n",
    "    assert os.path.exists(inference_filepath)\n",
    "    filenames = os.listdir(inference_filepath)\n",
    "    if '.DS_Store' in filenames:\n",
    "        filenames.remove('.DS_Store')\n",
    "    filenames = sorted(filenames, reverse=True)\n",
    "    testset = []\n",
    "    for idx, filename in enumerate(filenames):\n",
    "        if filename == \"inf_1211_to_1217.csv\":\n",
    "            continue\n",
    "        print(filename)\n",
    "        data = (pd.read_csv(inference_filepath + filename).values).tolist()\n",
    "        for single_data in data:\n",
    "            single_data = preprocessData(single_data)\n",
    "            testset.append(single_data)\n",
    "    return dataset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cce1a5c-bcde-444a-9972-ef8c27d33dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"data_filepath\": 'dataset_w_csv/',\n",
    "    # \"data_filepath\": '/kaggle/input/dataset-1201-new/dataset_w_csv/',\n",
    "    \"inference_filepath\": 'inference_w_csv/',\n",
    "    # \"inference_filepath\": '/kaggle/input/inference-1204/inference_csv/',\n",
    "    # \"inference_filepath\": '/kaggle/input/inference-new-1204/inference_w_csv/',\n",
    "    \"outputFilename\": \"results/prediction_RandomForest.csv\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81154cd4-8560-4f7a-be6f-6ee75a6e2d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitFeaturesLabels(dataset, type):\n",
    "    # month, day, weekday, hr, min, lat, lng, dist_g, dist_k, act, ratio, sbi, tot, title, act_title\n",
    "    if type == \"train\":\n",
    "        features = np.array(dataset[:,:8], dtype=float)\n",
    "        labels = np.array(dataset[:,8], dtype=float)\n",
    "        return features, labels\n",
    "    elif type == \"test\":\n",
    "        features = np.array(dataset[:,:8], dtype=float)\n",
    "        titles = []\n",
    "        tots = []\n",
    "        for single_data in dataset:\n",
    "            tots.append(int(single_data[8]))\n",
    "            titles.append(single_data[9])\n",
    "        return features, titles, tots\n",
    "    else:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2a1ecc-a96d-4372-aefc-b8c579c13683",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, testset = readDataset(config['data_filepath'], config['inference_filepath'])\n",
    "xtrain, ytrain = splitFeaturesLabels(np.array(dataset), \"train\")\n",
    "xtest, titles, tots = splitFeaturesLabels(np.array(testset), \"test\")\n",
    "\n",
    "xtrain = scale(xtrain)\n",
    "xtest = scale(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b60405-1d32-48af-bb76-011da36d5f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5b6e4c-0a48-45ac-b0d4-212934978383",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(xtrain))\n",
    "print(len(ytrain))\n",
    "print(len(xtest))\n",
    "print(len(titles))\n",
    "print(len(tots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4680689a-0154-491f-a481-174206bba85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(n_estimators=1300, verbose=1, n_jobs=-1)\n",
    "print(rfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542e5d22-2235-480c-9e69-f2ebe9654fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr.fit(xtrain, ytrain)\n",
    "\n",
    "score = rfr.score(xtrain, ytrain)\n",
    "print(\"R-squared:\", score) \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229994a2-95c1-4881-b8a0-93ff9999ee0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypreds = rfr.predict(xtest)\n",
    "\n",
    "assert len(ypreds) == len(titles) == len(tots)\n",
    "prediction = [['id','sbi']]\n",
    "for (pred, tot, title) in zip(ypreds, tots, titles):\n",
    "    prediction.append([title, pred*tot])\n",
    "\n",
    "with open(config['outputFilename'], 'w', newline='') as file:\n",
    "# Step 4: Using csv.writer to write the list to the CSV file\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(prediction) # Use writerows for nested list\n",
    "    \n",
    "print(\"output file written\")\n",
    "        \n",
    "# mse = mean_squared_error(ytest, ypred)\n",
    "# print(\"MSE: \", mse)\n",
    "# print(\"RMSE: \", mse*(1/2.0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871cb2c1-0111-4d6d-8a2b-ced5f1be7cad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
