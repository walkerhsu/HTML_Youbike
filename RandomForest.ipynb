{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce96f2fa-1280-4e95-b549-1dd2cdd63df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install scikit-learn \n",
    "# ! pip install numpy\n",
    "# ! pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc887209-0332-46d2-a7e3-356c726860fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn import set_config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39dabeb1-8bd1-438d-be92-45d76a867fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessData(singleData):\n",
    "    singleData[5] -= 24.5\n",
    "    singleData[6] -= 121\n",
    "    if singleData[3] == 0:\n",
    "        singleData[3] = 24\n",
    "    if singleData[4] == 0:\n",
    "        singleData[4] = 60\n",
    "    singleData[4] /= 60\n",
    "      \n",
    "    return singleData\n",
    "\n",
    "def readDataset(data_filepath, inference_filepath):\n",
    "    assert os.path.exists(data_filepath)\n",
    "    filenames = os.listdir(data_filepath)\n",
    "    if '.DS_Store' in filenames:\n",
    "        filenames.remove('.DS_Store')\n",
    "    filenames = sorted(filenames)\n",
    "    dataset = []\n",
    "    for idx, filename in enumerate(filenames):\n",
    "        data = (pd.read_csv(data_filepath + filename).values).tolist()\n",
    "        for single_data in data:\n",
    "            single_data = preprocessData(single_data)\n",
    "            dataset.append(single_data)\n",
    "\n",
    "    testDataset = []\n",
    "    assert os.path.exists(inference_filepath)\n",
    "    filenames = os.listdir(inference_filepath)\n",
    "    if '.DS_Store' in filenames:\n",
    "        filenames.remove('.DS_Store')\n",
    "    filenames = sorted(filenames, reverse=True)\n",
    "    testset = []\n",
    "    for idx, filename in enumerate(filenames):\n",
    "        if filename == \"inf_1211_to_1217.csv\":\n",
    "            continue\n",
    "        print(filename)\n",
    "        data = (pd.read_csv(inference_filepath + filename).values).tolist()\n",
    "        for single_data in data:\n",
    "            single_data = preprocessData(single_data)\n",
    "            testset.append(single_data)\n",
    "    return dataset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0cce1a5c-bcde-444a-9972-ef8c27d33dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"data_filepath\": 'dataset_w_with_distance/',\n",
    "    # \"data_filepath\": '/kaggle/input/dataset-1201-new/dataset_w_csv/',\n",
    "    \"inference_filepath\": 'inference_w_with_distance/',\n",
    "    # \"inference_filepath\": '/kaggle/input/inference-1204/inference_csv/',\n",
    "    # \"inference_filepath\": '/kaggle/input/inference-new-1204/inference_w_csv/',\n",
    "    \"outputFilename\": \"results/prediction_RandomForest.csv\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "81154cd4-8560-4f7a-be6f-6ee75a6e2d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitFeaturesLabels(dataset, type):\n",
    "    # month, day, weekday, hr, min, lat, lng, dist_g, dist_k, act, ratio, sbi, tot, title, act_title\n",
    "    if type == \"train\":\n",
    "        features = np.array(dataset[:,:10], dtype=float)\n",
    "        labels = np.array(dataset[:,10], dtype=float)\n",
    "        return features, labels\n",
    "    elif type == \"test\":\n",
    "        features = np.array(dataset[:,:10], dtype=float)\n",
    "        titles = []\n",
    "        tots = []\n",
    "        for single_data in dataset:\n",
    "            tots.append(int(single_data[10]))\n",
    "            titles.append(single_data[11])\n",
    "        return features, titles, tots\n",
    "    else:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6c2a1ecc-a96d-4372-aefc-b8c579c13683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf_1204_to_1210.csv\n",
      "inf_1021_to_1024.csv\n"
     ]
    }
   ],
   "source": [
    "dataset, testset = readDataset(config['data_filepath'], config['inference_filepath'])\n",
    "xtrain, ytrain = splitFeaturesLabels(np.array(dataset), \"train\")\n",
    "xtest, titles, tots = splitFeaturesLabels(np.array(testset), \"test\")\n",
    "\n",
    "xtrain = scale(xtrain)\n",
    "xtest = scale(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "18b60405-1d32-48af-bb76-011da36d5f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.75592895, -1.12823739, -1.3540064 ,  1.66132477,  1.22474487,\n",
       "        2.0071616 ,  0.84918385,  1.72662541, -2.46255408,  0.12176624])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d5b6e4c-0a48-45ac-b0d4-212934978383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "459984\n",
      "459984\n",
      "88704\n",
      "88704\n",
      "88704\n"
     ]
    }
   ],
   "source": [
    "print(len(xtrain))\n",
    "print(len(ytrain))\n",
    "print(len(xtest))\n",
    "print(len(titles))\n",
    "print(len(tots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4680689a-0154-491f-a481-174206bba85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor(n_estimators=1500, n_jobs=-1, verbose=1)\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(n_estimators=1500, verbose=1, n_jobs=-1)\n",
    "print(rfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "542e5d22-2235-480c-9e69-f2ebe9654fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   52.4s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1500 out of 1500 | elapsed:  9.9min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:   12.2s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:   29.3s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:   57.3s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:  1.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.9804217014720336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 1500 out of 1500 | elapsed:  1.8min finished\n"
     ]
    }
   ],
   "source": [
    "rfr.fit(xtrain, ytrain)\n",
    "\n",
    "score = rfr.score(xtrain, ytrain)\n",
    "print(\"R-squared:\", score) \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "229994a2-95c1-4881-b8a0-93ff9999ee0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:   18.7s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:   33.6s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:   54.9s\n",
      "[Parallel(n_jobs=8)]: Done 1500 out of 1500 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output file written\n"
     ]
    }
   ],
   "source": [
    "ypreds = rfr.predict(xtest)\n",
    "\n",
    "assert len(ypreds) == len(titles) == len(tots)\n",
    "prediction = [['id','sbi']]\n",
    "for (pred, tot, title) in zip(ypreds, tots, titles):\n",
    "    prediction.append([title, pred*tot])\n",
    "\n",
    "with open(config['outputFilename'], 'w', newline='') as file:\n",
    "# Step 4: Using csv.writer to write the list to the CSV file\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(prediction) # Use writerows for nested list\n",
    "    \n",
    "print(\"output file written\")\n",
    "        \n",
    "# mse = mean_squared_error(ytest, ypred)\n",
    "# print(\"MSE: \", mse)\n",
    "# print(\"RMSE: \", mse*(1/2.0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e775b4f2-5ee8-4fd2-a2b4-551d223f8592",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
