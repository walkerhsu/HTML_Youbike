<<<<<<< HEAD
<<<<<<< HEAD
{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Install Packages "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T05:58:12.602674Z","iopub.status.busy":"2023-11-30T05:58:12.602376Z","iopub.status.idle":"2023-11-30T05:58:12.608242Z","shell.execute_reply":"2023-11-30T05:58:12.606918Z","shell.execute_reply.started":"2023-11-30T05:58:12.602639Z"},"trusted":true},"outputs":[],"source":["!pip install scikit-learn\n","!pip install numpy\n","!pip install pandas\n","!pip install torch\n","!pip install tqdm"]},{"cell_type":"markdown","metadata":{},"source":["## Import Packages"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3886c10b-f7c4-47cf-8857-2f30cdcedb45","_uuid":"c82b120e-39f1-4533-9688-3a0b859a062f","collapsed":false,"execution":{"iopub.execute_input":"2023-11-30T05:58:16.782221Z","iopub.status.busy":"2023-11-30T05:58:16.781804Z","iopub.status.idle":"2023-11-30T05:58:21.094973Z","shell.execute_reply":"2023-11-30T05:58:21.094058Z","shell.execute_reply.started":"2023-11-30T05:58:16.782170Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n","\n","from tqdm import tqdm\n","import math\n","import random"]},{"cell_type":"markdown","metadata":{},"source":["## Useful Functions "]},{"cell_type":"markdown","metadata":{},"source":["### Set seeds"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def same_seeds(seed):\n","    random.seed(seed) \n","    np.random.seed(seed)  \n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed(seed)\n","        torch.cuda.manual_seed_all(seed) \n","    torch.backends.cudnn.benchmark = False\n","    torch.backends.cudnn.deterministic = True"]},{"cell_type":"markdown","metadata":{},"source":["### Read Dataset from CSV Files"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"590ecbce-8877-4ca8-ae7f-d7d83992502b","_uuid":"34f64581-b863-4aed-90cf-714ec8edcd5e","collapsed":false,"execution":{"iopub.execute_input":"2023-11-30T05:58:21.097231Z","iopub.status.busy":"2023-11-30T05:58:21.096766Z","iopub.status.idle":"2023-11-30T05:58:21.105189Z","shell.execute_reply":"2023-11-30T05:58:21.104139Z","shell.execute_reply.started":"2023-11-30T05:58:21.097171Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def readDataset(data_filepath):\n","    assert os.path.exists(data_filepath)\n","    filenames = os.listdir(data_filepath)\n","    if '.DS_Store' in filenames:\n","        filenames.remove('.DS_Store')\n","    filenames = sorted(filenames)\n","    train, valid = [], []\n","    decimalPoint = 10000\n","    \n","    for idx, filename in enumerate(filenames):\n","        data = (pd.read_csv(data_filepath + filename).values).tolist()\n","        if idx >= len(filenames) - 14:\n","            # validation\n","            for single_data in data:\n","                valid.append(single_data)\n","        else:\n","            #training\n","            for single_data in data:\n","                train.append(single_data)\n","    return train, valid"]},{"cell_type":"markdown","metadata":{},"source":["## My Youbike Dataset Class "]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d1f743cb-4af8-40f9-8491-c97b92210c97","_uuid":"24f46a6f-ebb4-4cab-b211-834442d0d02e","collapsed":false,"execution":{"iopub.execute_input":"2023-11-30T05:58:21.106896Z","iopub.status.busy":"2023-11-30T05:58:21.106529Z","iopub.status.idle":"2023-11-30T05:58:21.116961Z","shell.execute_reply":"2023-11-30T05:58:21.115935Z","shell.execute_reply.started":"2023-11-30T05:58:21.106862Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["class YoubikeDataset(Dataset):\n","    def __init__(self, data):\n","        super(YoubikeDataset, self).__init__()\n","        # [month, date, weekday, hr, min, lat, lng, act, ratio, sbi, tot, title, act_title]\n","        self.data = data\n","        self.datasize = len(self.data)\n","\n","    def __getitem__(self, idx):\n","        label = [self.data[idx][8]]\n","        features = self.data[idx][:8]\n","        return torch.FloatTensor(features), torch.FloatTensor(label)\n","\n","    def __len__(self):\n","        return self.datasize"]},{"cell_type":"markdown","metadata":{},"source":["## My Model(s)"]},{"cell_type":"markdown","metadata":{},"source":["### DNN model"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c9b009bb-f67b-4740-9bf0-14c4c57c597c","_uuid":"8064e40a-7ebd-4adc-a871-8786bb42c7b1","collapsed":false,"execution":{"iopub.execute_input":"2023-11-30T05:58:21.121254Z","iopub.status.busy":"2023-11-30T05:58:21.120912Z","iopub.status.idle":"2023-11-30T05:58:21.127838Z","shell.execute_reply":"2023-11-30T05:58:21.126845Z","shell.execute_reply.started":"2023-11-30T05:58:21.121226Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["class My_Model(nn.Module):\n","    def __init__(self, input_dim):\n","        super(My_Model, self).__init__()\n","        # TODO: modify model's structure, be aware of dimensions. \n","        self.layers = nn.Sequential(\n","            nn.Linear(input_dim, 4),\n","            nn.Sigmoid(),\n","            nn.Linear(4, 1),\n","            nn.Sigmoid(),\n","        )\n","\n","    def forward(self, x):\n","        x = self.layers(x)\n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["## Training function"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8eb27ae9-f1a0-48ec-b592-b30bbd58c010","_uuid":"86c145bf-8323-4e9b-9896-fd1a6fa34695","collapsed":false,"execution":{"iopub.execute_input":"2023-11-30T06:00:25.208840Z","iopub.status.busy":"2023-11-30T06:00:25.208429Z","iopub.status.idle":"2023-11-30T06:00:25.226216Z","shell.execute_reply":"2023-11-30T06:00:25.225215Z","shell.execute_reply.started":"2023-11-30T06:00:25.208807Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def train(model, config, train_loader, valid_loader, device):\n","    criterion = nn.MSELoss(reduction='mean') # Define your loss function, do not modify this.\n","    # criterion = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.SGD(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay']) \n","    scheduler = CosineAnnealingWarmRestarts(optimizer,T_0=1,T_mult=2)\n","    if not os.path.isdir(config[\"save_dir\"]):\n","        os.mkdir(config[\"save_dir\"]) # Create directory of saving models.\n","\n","    n_epochs, best_loss, step, early_stop_count = config['epochs'], math.inf, 0, 0\n","\n","    for epoch in range(n_epochs):\n","        model.train() # Set your model to train mode.\n","        loss_record = []\n","        print(scheduler.get_last_lr())\n","\n","        # tqdm is a package to visualize your training progress.\n","        train_pbar = tqdm(train_loader, position=0, leave=True)\n","\n","        for x, y in train_pbar:\n","            optimizer.zero_grad()               # Set gradient to zero.\n","            x, y = x.to(device), y.to(device)   # Move your data to device. \n","            pred = model(x) \n","            loss = criterion(pred, y)\n","            loss.backward()                     # Compute gradient(backpropagation).\n","            optimizer.step()                    # Update parameters.\n","            step += 1\n","            loss_record.append(loss.detach().item())\n","            \n","            # Display current epoch number and loss on tqdm progress bar.\n","            train_pbar.set_description(f'Epoch [{epoch+1}/{n_epochs}]')\n","            train_pbar.set_postfix({'loss': loss.detach().item()})\n","\n","        scheduler.step()\n","        mean_train_loss = sum(loss_record)/len(loss_record)\n","\n","        model.eval() # Set your model to evaluation mode.\n","        loss_record = []\n","        for x, y in valid_loader:\n","            x, y = x.to(device), y.to(device)\n","            with torch.no_grad():\n","                pred = model(x)\n","                loss = criterion(pred, y)\n","\n","            loss_record.append(loss.item())\n","            \n","        mean_valid_loss = sum(loss_record)/len(loss_record)\n","        print(f'Epoch [{epoch+1}/{n_epochs}]: Train loss: {mean_train_loss:.4f}, Valid loss: {mean_valid_loss:.4f}')\n","        # writer.add_scalar('Loss/valid', mean_valid_loss, step)\n","\n","        if mean_valid_loss < best_loss:\n","            best_loss = mean_valid_loss\n","            torch.save(model.state_dict(), config['save_dir'] + config['model_name']) # Save your best model\n","            print('Saving model with loss {:.3f}...'.format(best_loss))\n","            early_stop_count = 0\n","        else: \n","            early_stop_count += 1\n","\n","        if early_stop_count >= config['early_stop']:\n","            print('\\nModel is not improving, so we halt the training session.')\n","            print('best loss {:.3f}...'.format(best_loss))\n","            return"]},{"cell_type":"markdown","metadata":{},"source":["# Hyperparameters"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"050181da-4d1e-4cce-addc-868287bbf465","_uuid":"1642af7c-4541-401c-97cd-fd4aed575e53","collapsed":false,"execution":{"iopub.execute_input":"2023-11-30T05:58:21.148859Z","iopub.status.busy":"2023-11-30T05:58:21.148517Z","iopub.status.idle":"2023-11-30T05:58:21.227847Z","shell.execute_reply":"2023-11-30T05:58:21.226609Z","shell.execute_reply.started":"2023-11-30T05:58:21.148832Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["config = {\n","    \"batch_size\": 8,\n","#     \"data_filepath\": 'dataset_csv/',\n","    \"data_filepath\": '/kaggle/input/dataset-1129/dataset_csv/',\n","    \"epochs\": 60,\n","    \"learning_rate\": 5e-4,\n","    \"weight_decay\": 5e-3,\n","    \"save_dir\": \"./models/\",\n","    \"model_name\": \"1129-DNN.ckpt\",\n","    \"early_stop\":20,\n","    \"seeds\": 10901036\n","}\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"markdown","metadata":{},"source":["## Load Datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"58d5efaf-76ee-4332-9085-e6d1b623cfc5","_uuid":"c80b8a6f-f869-40d3-9822-05a3747b9ceb","collapsed":false,"execution":{"iopub.execute_input":"2023-11-30T05:58:21.229728Z","iopub.status.busy":"2023-11-30T05:58:21.229307Z","iopub.status.idle":"2023-11-30T05:58:23.619435Z","shell.execute_reply":"2023-11-30T05:58:23.618366Z","shell.execute_reply.started":"2023-11-30T05:58:21.229678Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["same_seeds(config[\"seeds\"])\n","train_data, valid_data = readDataset(config['data_filepath'])\n","print(f'train_data_size: {len(train_data)}, valid_data_size: {len(valid_data)}')\n","train_dataset, valid_dataset = YoubikeDataset(train_data), YoubikeDataset(valid_data)\n","train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\n","valid_loader = DataLoader(valid_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)"]},{"cell_type":"markdown","metadata":{},"source":["## Start Training"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"192b0a7e-9672-43b9-ae6c-b01f7f217a2f","_uuid":"0c61441f-52c7-4ecc-a3ac-d8c75362120a","collapsed":false,"execution":{"iopub.execute_input":"2023-11-30T06:00:27.679588Z","iopub.status.busy":"2023-11-30T06:00:27.679200Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["model = My_Model(input_dim=8).to(device) # put your model and data on the same computation device.\n","\n","train(model, config, train_loader, valid_loader, device)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4083080,"sourceId":7086646,"sourceType":"datasetVersion"}],"dockerImageVersionId":30587,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
=======
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d33d971-195e-488a-bb88-4b73f9bb852c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Users/walker/miniconda3/lib/python3.11/site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /Users/walker/miniconda3/lib/python3.11/site-packages (from scikit-learn) (1.26.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/walker/miniconda3/lib/python3.11/site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/walker/miniconda3/lib/python3.11/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/walker/miniconda3/lib/python3.11/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: numpy in /Users/walker/miniconda3/lib/python3.11/site-packages (1.26.0)\n",
      "Requirement already satisfied: pandas in /Users/walker/miniconda3/lib/python3.11/site-packages (2.1.3)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /Users/walker/miniconda3/lib/python3.11/site-packages (from pandas) (1.26.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/walker/miniconda3/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/walker/miniconda3/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/walker/miniconda3/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/walker/miniconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: torch in /Users/walker/miniconda3/lib/python3.11/site-packages (2.1.1)\n",
      "Requirement already satisfied: filelock in /Users/walker/miniconda3/lib/python3.11/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/walker/miniconda3/lib/python3.11/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in /Users/walker/miniconda3/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/walker/miniconda3/lib/python3.11/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/walker/miniconda3/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/walker/miniconda3/lib/python3.11/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/walker/miniconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/walker/miniconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: tqdm in /Users/walker/miniconda3/lib/python3.11/site-packages (4.65.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U scikit-learn\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install torch\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcd6cdd2-aefa-481e-8598-fb26036a1ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "038f801b-410f-47cf-8eec-c4b7339595d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readDataset(data_filepath):\n",
    "    assert os.path.exists(data_filepath)\n",
    "    filenames = os.listdir(data_filepath)\n",
    "    if '.DS_Store' in filenames:\n",
    "        filenames.remove('.DS_Store')\n",
    "    filenames = sorted(filenames)\n",
    "    train, valid = [], []\n",
    "    decimalPoint = 10000\n",
    "    \n",
    "    for idx, filename in enumerate(filenames):\n",
    "        data = (pd.read_csv(data_filepath + filename).values).tolist()\n",
    "        if idx >= len(filenames) - 7:\n",
    "            # validation\n",
    "            for single_data in data:\n",
    "                valid.append(single_data)\n",
    "        else:\n",
    "            #training\n",
    "            for single_data in data:\n",
    "                train.append(single_data)\n",
    "    return train, valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82750ee4-c0fa-4bea-90c4-374550434003",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoubikeDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        super(YoubikeDataset, self).__init__()\n",
    "        # [weekday, hr, min, lat, lng, act, ratio, sbi, tot, title, act_title]\n",
    "        self.data = data\n",
    "        self.datasize = len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = [self.data[idx][6]]\n",
    "        features = self.data[idx][:6]\n",
    "        return torch.FloatTensor(features), torch.FloatTensor(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.datasize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0368f002-4bdf-48f7-94cd-05ecc2838050",
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Model(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(My_Model, self).__init__()\n",
    "        # TODO: modify model's structure, be aware of dimensions. \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        x = x.squeeze(1) # (B, 1) -> (B)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4daba75a-1275-469e-add2-3526dee7c746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, config, train_loader, valid_loader, device):\n",
    "    criterion = nn.MSELoss(reduction='mean') # Define your loss function, do not modify this.\n",
    "    # criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay']) \n",
    "    if not os.path.isdir('./models'):\n",
    "        os.mkdir('./models') # Create directory of saving models.\n",
    "\n",
    "    n_epochs, best_loss, step, early_stop_count = config['epochs'], math.inf, 0, 0\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train() # Set your model to train mode.\n",
    "        loss_record = []\n",
    "\n",
    "        # tqdm is a package to visualize your training progress.\n",
    "        train_pbar = tqdm(train_loader, position=0, leave=True)\n",
    "\n",
    "        for x, y in train_pbar:\n",
    "            optimizer.zero_grad()               # Set gradient to zero.\n",
    "            x, y = x.to(device), y.to(device)   # Move your data to device. \n",
    "            pred = model(x)             \n",
    "            loss = criterion(pred, y)\n",
    "            loss.backward()                     # Compute gradient(backpropagation).\n",
    "            optimizer.step()                    # Update parameters.\n",
    "            step += 1\n",
    "            loss_record.append(loss.detach().item())\n",
    "            \n",
    "            # Display current epoch number and loss on tqdm progress bar.\n",
    "            train_pbar.set_description(f'Epoch [{epoch+1}/{n_epochs}]')\n",
    "            train_pbar.set_postfix({'loss': loss.detach().item()})\n",
    "\n",
    "        mean_train_loss = sum(loss_record)/len(loss_record)\n",
    "\n",
    "        model.eval() # Set your model to evaluation mode.\n",
    "        loss_record = []\n",
    "        for x, y in valid_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            with torch.no_grad():\n",
    "                pred = model(x)\n",
    "                loss = criterion(pred, y)\n",
    "\n",
    "            loss_record.append(loss.item())\n",
    "            \n",
    "        mean_valid_loss = sum(loss_record)/len(loss_record)\n",
    "        print(f'Epoch [{epoch+1}/{n_epochs}]: Train loss: {mean_train_loss:.4f}, Valid loss: {mean_valid_loss:.4f}')\n",
    "        # writer.add_scalar('Loss/valid', mean_valid_loss, step)\n",
    "\n",
    "        if mean_valid_loss < best_loss:\n",
    "            best_loss = mean_valid_loss\n",
    "            torch.save(model.state_dict(), config['save_path']) # Save your best model\n",
    "            print('Saving model with loss {:.3f}...'.format(best_loss))\n",
    "            early_stop_count = 0\n",
    "        else: \n",
    "            early_stop_count += 1\n",
    "\n",
    "        if early_stop_count >= config['early_stop']:\n",
    "            print('\\nModel is not improving, so we halt the training session.')\n",
    "            print('best loss {:.3f}...'.format(best_loss))\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13f82f52-bcc3-454c-aa09-94e82294865b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"batch_size\": 8,\n",
    "    \"data_filepath\": 'dataset_csv/',\n",
    "    \"epochs\": 2,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"weight_decay\": 5e-3,\n",
    "    \"save_path\": \"models\",\n",
    "    \"early_stop\":100,\n",
    "}\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8771522e-e822-4a38-8fa2-755c46980889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345072 54768\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data = readDataset(config['data_filepath'])\n",
    "print(len(train_data), len(valid_data))\n",
    "train_dataset, valid_dataset = YoubikeDataset(train_data), YoubikeDataset(valid_data)\n",
    "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=False, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=config['batch_size'], shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c712154-7aca-4a4d-8655-70a9586dcd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                       | 0/43134 [00:00<?, ?it/s]/Users/walker/miniconda3/lib/python3.11/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "Epoch [1/2]:  27%|█▎   | 11711/43134 [00:59<02:39, 197.10it/s, loss=1]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m My_Model(input_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;66;03m# put your model and data on the same computation device.\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 29\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, config, train_loader, valid_loader, device)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# Display current epoch number and loss on tqdm progress bar.\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     train_pbar\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 29\u001b[0m     \u001b[43mtrain_pbar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_postfix\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mloss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m mean_train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(loss_record)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(loss_record)\n\u001b[1;32m     33\u001b[0m model\u001b[38;5;241m.\u001b[39meval() \u001b[38;5;66;03m# Set your model to evaluation mode.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tqdm/std.py:1428\u001b[0m, in \u001b[0;36mtqdm.set_postfix\u001b[0;34m(self, ordered_dict, refresh, **kwargs)\u001b[0m\n\u001b[1;32m   1425\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostfix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(key \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m postfix[key]\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m   1426\u001b[0m                          \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m postfix\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m   1427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m refresh:\n\u001b[0;32m-> 1428\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrefresh\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tqdm/std.py:1344\u001b[0m, in \u001b[0;36mtqdm.refresh\u001b[0;34m(self, nolock, lock_args)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1343\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39macquire()\n\u001b[0;32m-> 1344\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nolock:\n\u001b[1;32m   1346\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tqdm/std.py:1492\u001b[0m, in \u001b[0;36mtqdm.display\u001b[0;34m(self, msg, pos)\u001b[0m\n\u001b[1;32m   1490\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pos:\n\u001b[1;32m   1491\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmoveto(pos)\n\u001b[0;32m-> 1492\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__str__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pos:\n\u001b[1;32m   1494\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmoveto(\u001b[38;5;241m-\u001b[39mpos)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tqdm/std.py:347\u001b[0m, in \u001b[0;36mtqdm.status_printer.<locals>.print_status\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_status\u001b[39m(s):\n\u001b[1;32m    346\u001b[0m     len_s \u001b[38;5;241m=\u001b[39m disp_len(s)\n\u001b[0;32m--> 347\u001b[0m     \u001b[43mfp_write\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\r\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlast_len\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlen_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m     last_len[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m len_s\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tqdm/std.py:341\u001b[0m, in \u001b[0;36mtqdm.status_printer.<locals>.fp_write\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfp_write\u001b[39m(s):\n\u001b[1;32m    340\u001b[0m     fp\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;28mstr\u001b[39m(s))\n\u001b[0;32m--> 341\u001b[0m     \u001b[43mfp_flush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tqdm/utils.py:127\u001b[0m, in \u001b[0;36mDisableOnWriteError.disable_on_exception.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m5\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/ipykernel/iostream.py:578\u001b[0m, in \u001b[0;36mOutStream.flush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_thread\u001b[38;5;241m.\u001b[39mschedule(evt\u001b[38;5;241m.\u001b[39mset)\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;66;03m# and give a timeout to avoid\u001b[39;00m\n\u001b[0;32m--> 578\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mevt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush_timeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;66;03m# write directly to __stderr__ instead of warning because\u001b[39;00m\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;66;03m# if this is happening sys.stderr may be the problem.\u001b[39;00m\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIOStream.flush timed out\u001b[39m\u001b[38;5;124m\"\u001b[39m, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39m__stderr__)\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/threading.py:622\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    620\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 622\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = My_Model(input_dim=6).to(device) # put your model and data on the same computation device.\n",
    "\n",
    "train(model, config, train_loader, valid_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69eac894-56e5-4255-a117-70391564483e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
>>>>>>> 9f91bf4 (:construction: add DNN model notebook)
=======
{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Install Packages "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T05:58:12.602674Z","iopub.status.busy":"2023-11-30T05:58:12.602376Z","iopub.status.idle":"2023-11-30T05:58:12.608242Z","shell.execute_reply":"2023-11-30T05:58:12.606918Z","shell.execute_reply.started":"2023-11-30T05:58:12.602639Z"},"trusted":true},"outputs":[],"source":["!pip install scikit-learn\n","!pip install numpy\n","!pip install pandas\n","!pip install torch\n","!pip install tqdm"]},{"cell_type":"markdown","metadata":{},"source":["## Import Packages"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3886c10b-f7c4-47cf-8857-2f30cdcedb45","_uuid":"c82b120e-39f1-4533-9688-3a0b859a062f","collapsed":false,"execution":{"iopub.execute_input":"2023-11-30T05:58:16.782221Z","iopub.status.busy":"2023-11-30T05:58:16.781804Z","iopub.status.idle":"2023-11-30T05:58:21.094973Z","shell.execute_reply":"2023-11-30T05:58:21.094058Z","shell.execute_reply.started":"2023-11-30T05:58:16.782170Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n","\n","from tqdm import tqdm\n","import math\n","import random"]},{"cell_type":"markdown","metadata":{},"source":["## Useful Functions "]},{"cell_type":"markdown","metadata":{},"source":["### Set seeds"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def same_seeds(seed):\n","    random.seed(seed) \n","    np.random.seed(seed)  \n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed(seed)\n","        torch.cuda.manual_seed_all(seed) \n","    torch.backends.cudnn.benchmark = False\n","    torch.backends.cudnn.deterministic = True"]},{"cell_type":"markdown","metadata":{},"source":["### Read Dataset from CSV Files"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"590ecbce-8877-4ca8-ae7f-d7d83992502b","_uuid":"34f64581-b863-4aed-90cf-714ec8edcd5e","collapsed":false,"execution":{"iopub.execute_input":"2023-11-30T05:58:21.097231Z","iopub.status.busy":"2023-11-30T05:58:21.096766Z","iopub.status.idle":"2023-11-30T05:58:21.105189Z","shell.execute_reply":"2023-11-30T05:58:21.104139Z","shell.execute_reply.started":"2023-11-30T05:58:21.097171Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def readDataset(data_filepath):\n","    assert os.path.exists(data_filepath)\n","    filenames = os.listdir(data_filepath)\n","    if '.DS_Store' in filenames:\n","        filenames.remove('.DS_Store')\n","    filenames = sorted(filenames)\n","    train, valid = [], []\n","    decimalPoint = 10000\n","    \n","    for idx, filename in enumerate(filenames):\n","        data = (pd.read_csv(data_filepath + filename).values).tolist()\n","        if idx >= len(filenames) - 14:\n","            # validation\n","            for single_data in data:\n","                valid.append(single_data)\n","        else:\n","            #training\n","            for single_data in data:\n","                train.append(single_data)\n","    return train, valid"]},{"cell_type":"markdown","metadata":{},"source":["## My Youbike Dataset Class "]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d1f743cb-4af8-40f9-8491-c97b92210c97","_uuid":"24f46a6f-ebb4-4cab-b211-834442d0d02e","collapsed":false,"execution":{"iopub.execute_input":"2023-11-30T05:58:21.106896Z","iopub.status.busy":"2023-11-30T05:58:21.106529Z","iopub.status.idle":"2023-11-30T05:58:21.116961Z","shell.execute_reply":"2023-11-30T05:58:21.115935Z","shell.execute_reply.started":"2023-11-30T05:58:21.106862Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["class YoubikeDataset(Dataset):\n","    def __init__(self, data):\n","        super(YoubikeDataset, self).__init__()\n","        # [month, date, weekday, hr, min, lat, lng, act, ratio, sbi, tot, title, act_title]\n","        self.data = data\n","        self.datasize = len(self.data)\n","\n","    def __getitem__(self, idx):\n","        label = [self.data[idx][8]]\n","        features = self.data[idx][:8]\n","        return torch.FloatTensor(features), torch.FloatTensor(label)\n","\n","    def __len__(self):\n","        return self.datasize"]},{"cell_type":"markdown","metadata":{},"source":["## My Model(s)"]},{"cell_type":"markdown","metadata":{},"source":["### DNN model"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c9b009bb-f67b-4740-9bf0-14c4c57c597c","_uuid":"8064e40a-7ebd-4adc-a871-8786bb42c7b1","collapsed":false,"execution":{"iopub.execute_input":"2023-11-30T05:58:21.121254Z","iopub.status.busy":"2023-11-30T05:58:21.120912Z","iopub.status.idle":"2023-11-30T05:58:21.127838Z","shell.execute_reply":"2023-11-30T05:58:21.126845Z","shell.execute_reply.started":"2023-11-30T05:58:21.121226Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["class My_Model(nn.Module):\n","    def __init__(self, input_dim):\n","        super(My_Model, self).__init__()\n","        # TODO: modify model's structure, be aware of dimensions. \n","        self.layers = nn.Sequential(\n","            nn.Linear(input_dim, 4),\n","            nn.Sigmoid(),\n","            nn.Linear(4, 1),\n","            nn.Sigmoid(),\n","        )\n","\n","    def forward(self, x):\n","        x = self.layers(x)\n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["## Training function"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8eb27ae9-f1a0-48ec-b592-b30bbd58c010","_uuid":"86c145bf-8323-4e9b-9896-fd1a6fa34695","collapsed":false,"execution":{"iopub.execute_input":"2023-11-30T06:00:25.208840Z","iopub.status.busy":"2023-11-30T06:00:25.208429Z","iopub.status.idle":"2023-11-30T06:00:25.226216Z","shell.execute_reply":"2023-11-30T06:00:25.225215Z","shell.execute_reply.started":"2023-11-30T06:00:25.208807Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def train(model, config, train_loader, valid_loader, device):\n","    criterion = nn.MSELoss(reduction='mean') # Define your loss function, do not modify this.\n","    # criterion = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.SGD(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay']) \n","    scheduler = CosineAnnealingWarmRestarts(optimizer,T_0=1,T_mult=2)\n","    if not os.path.isdir(config[\"save_dir\"]):\n","        os.mkdir(config[\"save_dir\"]) # Create directory of saving models.\n","\n","    n_epochs, best_loss, step, early_stop_count = config['epochs'], math.inf, 0, 0\n","\n","    for epoch in range(n_epochs):\n","        model.train() # Set your model to train mode.\n","        loss_record = []\n","        print(scheduler.get_last_lr())\n","\n","        # tqdm is a package to visualize your training progress.\n","        train_pbar = tqdm(train_loader, position=0, leave=True)\n","\n","        for x, y in train_pbar:\n","            optimizer.zero_grad()               # Set gradient to zero.\n","            x, y = x.to(device), y.to(device)   # Move your data to device. \n","            pred = model(x) \n","            loss = criterion(pred, y)\n","            loss.backward()                     # Compute gradient(backpropagation).\n","            optimizer.step()                    # Update parameters.\n","            step += 1\n","            loss_record.append(loss.detach().item())\n","            \n","            # Display current epoch number and loss on tqdm progress bar.\n","            train_pbar.set_description(f'Epoch [{epoch+1}/{n_epochs}]')\n","            train_pbar.set_postfix({'loss': loss.detach().item()})\n","\n","        scheduler.step()\n","        mean_train_loss = sum(loss_record)/len(loss_record)\n","\n","        model.eval() # Set your model to evaluation mode.\n","        loss_record = []\n","        for x, y in valid_loader:\n","            x, y = x.to(device), y.to(device)\n","            with torch.no_grad():\n","                pred = model(x)\n","                loss = criterion(pred, y)\n","\n","            loss_record.append(loss.item())\n","            \n","        mean_valid_loss = sum(loss_record)/len(loss_record)\n","        print(f'Epoch [{epoch+1}/{n_epochs}]: Train loss: {mean_train_loss:.4f}, Valid loss: {mean_valid_loss:.4f}')\n","        # writer.add_scalar('Loss/valid', mean_valid_loss, step)\n","\n","        if mean_valid_loss < best_loss:\n","            best_loss = mean_valid_loss\n","            torch.save(model.state_dict(), config['save_dir'] + config['model_name']) # Save your best model\n","            print('Saving model with loss {:.3f}...'.format(best_loss))\n","            early_stop_count = 0\n","        else: \n","            early_stop_count += 1\n","\n","        if early_stop_count >= config['early_stop']:\n","            print('\\nModel is not improving, so we halt the training session.')\n","            print('best loss {:.3f}...'.format(best_loss))\n","            return"]},{"cell_type":"markdown","metadata":{},"source":["# Hyperparameters"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"050181da-4d1e-4cce-addc-868287bbf465","_uuid":"1642af7c-4541-401c-97cd-fd4aed575e53","collapsed":false,"execution":{"iopub.execute_input":"2023-11-30T05:58:21.148859Z","iopub.status.busy":"2023-11-30T05:58:21.148517Z","iopub.status.idle":"2023-11-30T05:58:21.227847Z","shell.execute_reply":"2023-11-30T05:58:21.226609Z","shell.execute_reply.started":"2023-11-30T05:58:21.148832Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["config = {\n","    \"batch_size\": 8,\n","#     \"data_filepath\": 'dataset_csv/',\n","    \"data_filepath\": '/kaggle/input/dataset-1129/dataset_csv/',\n","    \"epochs\": 60,\n","    \"learning_rate\": 5e-4,\n","    \"weight_decay\": 5e-3,\n","    \"save_dir\": \"./models/\",\n","    \"model_name\": \"1129-DNN.ckpt\",\n","    \"early_stop\":20,\n","    \"seeds\": 10901036\n","}\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"markdown","metadata":{},"source":["## Load Datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"58d5efaf-76ee-4332-9085-e6d1b623cfc5","_uuid":"c80b8a6f-f869-40d3-9822-05a3747b9ceb","collapsed":false,"execution":{"iopub.execute_input":"2023-11-30T05:58:21.229728Z","iopub.status.busy":"2023-11-30T05:58:21.229307Z","iopub.status.idle":"2023-11-30T05:58:23.619435Z","shell.execute_reply":"2023-11-30T05:58:23.618366Z","shell.execute_reply.started":"2023-11-30T05:58:21.229678Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["same_seeds(config[\"seeds\"])\n","train_data, valid_data = readDataset(config['data_filepath'])\n","print(f'train_data_size: {len(train_data)}, valid_data_size: {len(valid_data)}')\n","train_dataset, valid_dataset = YoubikeDataset(train_data), YoubikeDataset(valid_data)\n","train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\n","valid_loader = DataLoader(valid_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)"]},{"cell_type":"markdown","metadata":{},"source":["## Start Training"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"192b0a7e-9672-43b9-ae6c-b01f7f217a2f","_uuid":"0c61441f-52c7-4ecc-a3ac-d8c75362120a","collapsed":false,"execution":{"iopub.execute_input":"2023-11-30T06:00:27.679588Z","iopub.status.busy":"2023-11-30T06:00:27.679200Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["model = My_Model(input_dim=8).to(device) # put your model and data on the same computation device.\n","\n","train(model, config, train_loader, valid_loader, device)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4083080,"sourceId":7086646,"sourceType":"datasetVersion"}],"dockerImageVersionId":30587,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
>>>>>>> 0307a48 (:construction: trainable but loss strange)
