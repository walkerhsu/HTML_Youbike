{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Install Packages "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T05:58:12.602674Z","iopub.status.busy":"2023-11-30T05:58:12.602376Z","iopub.status.idle":"2023-11-30T05:58:12.608242Z","shell.execute_reply":"2023-11-30T05:58:12.606918Z","shell.execute_reply.started":"2023-11-30T05:58:12.602639Z"},"trusted":true},"outputs":[],"source":["!pip install scikit-learn\n","!pip install numpy\n","!pip install pandas\n","!pip install torch\n","!pip install tqdm"]},{"cell_type":"markdown","metadata":{},"source":["## Import Packages"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3886c10b-f7c4-47cf-8857-2f30cdcedb45","_uuid":"c82b120e-39f1-4533-9688-3a0b859a062f","collapsed":false,"execution":{"iopub.execute_input":"2023-11-30T05:58:16.782221Z","iopub.status.busy":"2023-11-30T05:58:16.781804Z","iopub.status.idle":"2023-11-30T05:58:21.094973Z","shell.execute_reply":"2023-11-30T05:58:21.094058Z","shell.execute_reply.started":"2023-11-30T05:58:16.782170Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n","\n","from tqdm import tqdm\n","import math\n","import random"]},{"cell_type":"markdown","metadata":{},"source":["## Useful Functions "]},{"cell_type":"markdown","metadata":{},"source":["### Set seeds"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def same_seeds(seed):\n","    random.seed(seed) \n","    np.random.seed(seed)  \n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed(seed)\n","        torch.cuda.manual_seed_all(seed) \n","    torch.backends.cudnn.benchmark = False\n","    torch.backends.cudnn.deterministic = True"]},{"cell_type":"markdown","metadata":{},"source":["### Read Dataset from CSV Files"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"590ecbce-8877-4ca8-ae7f-d7d83992502b","_uuid":"34f64581-b863-4aed-90cf-714ec8edcd5e","collapsed":false,"execution":{"iopub.execute_input":"2023-11-30T05:58:21.097231Z","iopub.status.busy":"2023-11-30T05:58:21.096766Z","iopub.status.idle":"2023-11-30T05:58:21.105189Z","shell.execute_reply":"2023-11-30T05:58:21.104139Z","shell.execute_reply.started":"2023-11-30T05:58:21.097171Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def readDataset(data_filepath):\n","    assert os.path.exists(data_filepath)\n","    filenames = os.listdir(data_filepath)\n","    if '.DS_Store' in filenames:\n","        filenames.remove('.DS_Store')\n","    filenames = sorted(filenames)\n","    train, valid = [], []\n","    decimalPoint = 10000\n","    \n","    for idx, filename in enumerate(filenames):\n","        data = (pd.read_csv(data_filepath + filename).values).tolist()\n","        if idx >= len(filenames) - 14:\n","            # validation\n","            for single_data in data:\n","                valid.append(single_data)\n","        else:\n","            #training\n","            for single_data in data:\n","                train.append(single_data)\n","    return train, valid"]},{"cell_type":"markdown","metadata":{},"source":["## My Youbike Dataset Class "]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d1f743cb-4af8-40f9-8491-c97b92210c97","_uuid":"24f46a6f-ebb4-4cab-b211-834442d0d02e","collapsed":false,"execution":{"iopub.execute_input":"2023-11-30T05:58:21.106896Z","iopub.status.busy":"2023-11-30T05:58:21.106529Z","iopub.status.idle":"2023-11-30T05:58:21.116961Z","shell.execute_reply":"2023-11-30T05:58:21.115935Z","shell.execute_reply.started":"2023-11-30T05:58:21.106862Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["class YoubikeDataset(Dataset):\n","    def __init__(self, data):\n","        super(YoubikeDataset, self).__init__()\n","        # [month, date, weekday, hr, min, lat, lng, act, ratio, sbi, tot, title, act_title]\n","        self.data = data\n","        self.datasize = len(self.data)\n","\n","    def __getitem__(self, idx):\n","        label = [self.data[idx][8]]\n","        features = self.data[idx][:8]\n","        return torch.FloatTensor(features), torch.FloatTensor(label)\n","\n","    def __len__(self):\n","        return self.datasize"]},{"cell_type":"markdown","metadata":{},"source":["## My Model(s)"]},{"cell_type":"markdown","metadata":{},"source":["### DNN model"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c9b009bb-f67b-4740-9bf0-14c4c57c597c","_uuid":"8064e40a-7ebd-4adc-a871-8786bb42c7b1","collapsed":false,"execution":{"iopub.execute_input":"2023-11-30T05:58:21.121254Z","iopub.status.busy":"2023-11-30T05:58:21.120912Z","iopub.status.idle":"2023-11-30T05:58:21.127838Z","shell.execute_reply":"2023-11-30T05:58:21.126845Z","shell.execute_reply.started":"2023-11-30T05:58:21.121226Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["class My_Model(nn.Module):\n","    def __init__(self, input_dim):\n","        super(My_Model, self).__init__()\n","        # TODO: modify model's structure, be aware of dimensions. \n","        self.layers = nn.Sequential(\n","            nn.Linear(input_dim, 4),\n","            nn.Sigmoid(),\n","            nn.Linear(4, 1),\n","            nn.Sigmoid(),\n","        )\n","\n","    def forward(self, x):\n","        x = self.layers(x)\n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["## Training function"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8eb27ae9-f1a0-48ec-b592-b30bbd58c010","_uuid":"86c145bf-8323-4e9b-9896-fd1a6fa34695","collapsed":false,"execution":{"iopub.execute_input":"2023-11-30T06:00:25.208840Z","iopub.status.busy":"2023-11-30T06:00:25.208429Z","iopub.status.idle":"2023-11-30T06:00:25.226216Z","shell.execute_reply":"2023-11-30T06:00:25.225215Z","shell.execute_reply.started":"2023-11-30T06:00:25.208807Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def train(model, config, train_loader, valid_loader, device):\n","    criterion = nn.MSELoss(reduction='mean') # Define your loss function, do not modify this.\n","    # criterion = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.SGD(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay']) \n","    scheduler = CosineAnnealingWarmRestarts(optimizer,T_0=1,T_mult=2)\n","    if not os.path.isdir(config[\"save_dir\"]):\n","        os.mkdir(config[\"save_dir\"]) # Create directory of saving models.\n","\n","    n_epochs, best_loss, step, early_stop_count = config['epochs'], math.inf, 0, 0\n","\n","    for epoch in range(n_epochs):\n","        model.train() # Set your model to train mode.\n","        loss_record = []\n","        print(scheduler.get_last_lr())\n","\n","        # tqdm is a package to visualize your training progress.\n","        train_pbar = tqdm(train_loader, position=0, leave=True)\n","\n","        for x, y in train_pbar:\n","            optimizer.zero_grad()               # Set gradient to zero.\n","            x, y = x.to(device), y.to(device)   # Move your data to device. \n","            pred = model(x) \n","            loss = criterion(pred, y)\n","            loss.backward()                     # Compute gradient(backpropagation).\n","            optimizer.step()                    # Update parameters.\n","            step += 1\n","            loss_record.append(loss.detach().item())\n","            \n","            # Display current epoch number and loss on tqdm progress bar.\n","            train_pbar.set_description(f'Epoch [{epoch+1}/{n_epochs}]')\n","            train_pbar.set_postfix({'loss': loss.detach().item()})\n","\n","        scheduler.step()\n","        mean_train_loss = sum(loss_record)/len(loss_record)\n","\n","        model.eval() # Set your model to evaluation mode.\n","        loss_record = []\n","        for x, y in valid_loader:\n","            x, y = x.to(device), y.to(device)\n","            with torch.no_grad():\n","                pred = model(x)\n","                loss = criterion(pred, y)\n","\n","            loss_record.append(loss.item())\n","            \n","        mean_valid_loss = sum(loss_record)/len(loss_record)\n","        print(f'Epoch [{epoch+1}/{n_epochs}]: Train loss: {mean_train_loss:.4f}, Valid loss: {mean_valid_loss:.4f}')\n","        # writer.add_scalar('Loss/valid', mean_valid_loss, step)\n","\n","        if mean_valid_loss < best_loss:\n","            best_loss = mean_valid_loss\n","            torch.save(model.state_dict(), config['save_dir'] + config['model_name']) # Save your best model\n","            print('Saving model with loss {:.3f}...'.format(best_loss))\n","            early_stop_count = 0\n","        else: \n","            early_stop_count += 1\n","\n","        if early_stop_count >= config['early_stop']:\n","            print('\\nModel is not improving, so we halt the training session.')\n","            print('best loss {:.3f}...'.format(best_loss))\n","            return"]},{"cell_type":"markdown","metadata":{},"source":["# Hyperparameters"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"050181da-4d1e-4cce-addc-868287bbf465","_uuid":"1642af7c-4541-401c-97cd-fd4aed575e53","collapsed":false,"execution":{"iopub.execute_input":"2023-11-30T05:58:21.148859Z","iopub.status.busy":"2023-11-30T05:58:21.148517Z","iopub.status.idle":"2023-11-30T05:58:21.227847Z","shell.execute_reply":"2023-11-30T05:58:21.226609Z","shell.execute_reply.started":"2023-11-30T05:58:21.148832Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["config = {\n","    \"batch_size\": 8,\n","#     \"data_filepath\": 'dataset_csv/',\n","    \"data_filepath\": '/kaggle/input/dataset-1129/dataset_csv/',\n","    \"epochs\": 60,\n","    \"learning_rate\": 5e-4,\n","    \"weight_decay\": 5e-3,\n","    \"save_dir\": \"./models/\",\n","    \"model_name\": \"1129-DNN.ckpt\",\n","    \"early_stop\":20,\n","    \"seeds\": 10901036\n","}\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"markdown","metadata":{},"source":["## Load Datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"58d5efaf-76ee-4332-9085-e6d1b623cfc5","_uuid":"c80b8a6f-f869-40d3-9822-05a3747b9ceb","collapsed":false,"execution":{"iopub.execute_input":"2023-11-30T05:58:21.229728Z","iopub.status.busy":"2023-11-30T05:58:21.229307Z","iopub.status.idle":"2023-11-30T05:58:23.619435Z","shell.execute_reply":"2023-11-30T05:58:23.618366Z","shell.execute_reply.started":"2023-11-30T05:58:21.229678Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["same_seeds(config[\"seeds\"])\n","train_data, valid_data = readDataset(config['data_filepath'])\n","print(f'train_data_size: {len(train_data)}, valid_data_size: {len(valid_data)}')\n","train_dataset, valid_dataset = YoubikeDataset(train_data), YoubikeDataset(valid_data)\n","train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\n","valid_loader = DataLoader(valid_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)"]},{"cell_type":"markdown","metadata":{},"source":["## Start Training"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"192b0a7e-9672-43b9-ae6c-b01f7f217a2f","_uuid":"0c61441f-52c7-4ecc-a3ac-d8c75362120a","collapsed":false,"execution":{"iopub.execute_input":"2023-11-30T06:00:27.679588Z","iopub.status.busy":"2023-11-30T06:00:27.679200Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["model = My_Model(input_dim=8).to(device) # put your model and data on the same computation device.\n","\n","train(model, config, train_loader, valid_loader, device)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4083080,"sourceId":7086646,"sourceType":"datasetVersion"}],"dockerImageVersionId":30587,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
