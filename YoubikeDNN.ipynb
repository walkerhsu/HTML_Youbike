{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"1da9459b-97aa-49e8-a49f-dcf71454e6be","_uuid":"3daf6498-869d-4c38-85c9-059461e0e4f5","trusted":true},"source":["## Install Packages"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"19e73ea7-9734-48a3-8e58-998b463d823a","_uuid":"ef6916a0-4fb6-4fa5-8ab1-e7002f8f90e8","collapsed":false,"execution":{"iopub.execute_input":"2023-12-02T14:41:46.266799Z","iopub.status.busy":"2023-12-02T14:41:46.266545Z","iopub.status.idle":"2023-12-02T14:41:46.271603Z","shell.execute_reply":"2023-12-02T14:41:46.270708Z","shell.execute_reply.started":"2023-12-02T14:41:46.266776Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# !pip install scikit-learn\n","# !pip install numpy\n","# !pip install pandas\n","# !pip install torch\n","# !pip install tqdm"]},{"cell_type":"markdown","metadata":{"_cell_guid":"d329f981-1410-4509-93bd-06d0c0e5587f","_uuid":"4e86ec41-5682-4a99-958f-78c9432de6fd","trusted":true},"source":["## Import Packages"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6f79ac2c-b8aa-4c4e-89a2-eadb1f6773b8","_uuid":"a616ae38-2872-439e-90b4-b2933d651dcc","collapsed":false,"execution":{"iopub.execute_input":"2023-12-02T14:41:46.277752Z","iopub.status.busy":"2023-12-02T14:41:46.277482Z","iopub.status.idle":"2023-12-02T14:41:52.558772Z","shell.execute_reply":"2023-12-02T14:41:52.557977Z","shell.execute_reply.started":"2023-12-02T14:41:46.277728Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n","\n","from tqdm import tqdm\n","import math\n","import random\n","import csv"]},{"cell_type":"markdown","metadata":{"_cell_guid":"160c79a0-0e08-4b10-87e7-f43bc011e075","_uuid":"e860ed3f-8bce-44e1-9a78-429f6dbe4120","trusted":true},"source":["## Useful Functions"]},{"cell_type":"markdown","metadata":{"_cell_guid":"30712a16-3f89-4c31-9e38-a1128ea15066","_uuid":"80ee07e4-d6bb-4a9d-854a-41467981e0fa","trusted":true},"source":["### Set seeds"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"983e1f65-4f48-400f-ac54-802c107405bc","_uuid":"eaa743f2-5526-4764-af65-f369102c673b","collapsed":false,"execution":{"iopub.execute_input":"2023-12-02T14:41:52.561100Z","iopub.status.busy":"2023-12-02T14:41:52.560566Z","iopub.status.idle":"2023-12-02T14:41:52.567341Z","shell.execute_reply":"2023-12-02T14:41:52.566193Z","shell.execute_reply.started":"2023-12-02T14:41:52.561062Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def same_seeds(seed):\n","    random.seed(seed) \n","    np.random.seed(seed)  \n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed(seed)\n","        torch.cuda.manual_seed_all(seed) \n","    torch.backends.cudnn.benchmark = False\n","    torch.backends.cudnn.deterministic = True"]},{"cell_type":"markdown","metadata":{"_cell_guid":"e4127685-9339-4652-8ac5-d3fd29d18a36","_uuid":"396cd262-6b3a-4a4b-ba53-8fadab4d4e7d","trusted":true},"source":["### Read Dataset from CSV Files"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"35f220f2-1249-408b-825a-96e55a1c67e1","_uuid":"fd04738f-6f2b-44ab-a590-be3da6a10d4b","collapsed":false,"execution":{"iopub.execute_input":"2023-12-02T14:41:52.568814Z","iopub.status.busy":"2023-12-02T14:41:52.568531Z","iopub.status.idle":"2023-12-02T14:41:52.585560Z","shell.execute_reply":"2023-12-02T14:41:52.584683Z","shell.execute_reply.started":"2023-12-02T14:41:52.568789Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def preprocessData(previousData, data, dataType):\n","    preprocessedData = []\n","    currentDate = []\n","    dateData = []\n","    dateLabel = []\n","    \n","    for singleData in data:\n","        singleData[5] -= 24.5\n","        singleData[6] -= 121\n","        singleData[4] /= 60\n","        if len(currentDate) == 0:\n","            currentDate = [singleData[0], singleData[1], singleData[2], singleData[3], singleData[4]]\n","            dateData.append([singleData[5], singleData[6], singleData[7]])\n","            dateLabel.append(singleData[8])\n","            if dataType == 'test':\n","                dateLabel.append(singleData[9])\n","        elif currentDate == [singleData[0], singleData[1], singleData[2], singleData[3], singleData[4]]:\n","            dateData.append([singleData[5], singleData[6], singleData[7]])\n","            dateLabel.append(singleData[8])\n","            if dataType == 'test':\n","                dateLabel.append(singleData[9])\n","        else:\n","            dateData = list(np.concatenate(dateData).flat)\n","            preprocessedData.append(dateData+currentDate+dateLabel)\n","            currentDate = [singleData[0], singleData[1], singleData[2], singleData[3], singleData[4]]\n","            dateData = [[singleData[5], singleData[6], singleData[7]]]\n","            dateLabel = [singleData[8]]\n","            if dataType == 'test':\n","                dateLabel.append(singleData[9])\n","                \n","    dateData = list(np.concatenate(dateData).flat)\n","    preprocessedData.append(dateData+currentDate+dateLabel)\n","    \n","    for singlePreprocessedData in preprocessedData:\n","        previousData.append(singlePreprocessedData)\n","    return previousData\n","\n","def readDataset(data_filepath, inference_filepath):\n","    assert os.path.exists(data_filepath)\n","    filenames = os.listdir(data_filepath)\n","    if '.DS_Store' in filenames:\n","        filenames.remove('.DS_Store')\n","    filenames = sorted(filenames)\n","    train, valid, test = [], [], []\n","    for idx, filename in enumerate(filenames):\n","        data = (pd.read_csv(data_filepath + filename).values).tolist()\n","        if idx >= len(filenames) - 14:\n","            # validation\n","            valid = preprocessData(valid, data, 'valid')\n","        else:\n","            #training\n","            train = preprocessData(train, data, 'train')\n","    \n","    assert os.path.exists(inference_filepath)\n","    filenames = os.listdir(inference_filepath)\n","    if '.DS_Store' in filenames:\n","        filenames.remove('.DS_Store')\n","    filenames = sorted(filenames, reverse=True)\n","    test = []\n","    for idx, filename in enumerate(filenames):\n","        print(filename)\n","        data = (pd.read_csv(inference_filepath + filename).values).tolist()\n","        test = preprocessData(test, data, 'test')\n","    return train, valid, test"]},{"cell_type":"markdown","metadata":{"_cell_guid":"99467969-70fa-4934-8864-746e19831d3a","_uuid":"47be862a-ead4-4c40-be1c-57099c557c16","trusted":true},"source":["## My Youbike Dataset Class"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"98766ab9-dc06-40cc-bd41-90a650baa3bc","_uuid":"5cb83efb-01ca-4808-9c64-d339112a88fd","collapsed":false,"execution":{"iopub.execute_input":"2023-12-02T14:41:52.588014Z","iopub.status.busy":"2023-12-02T14:41:52.587735Z","iopub.status.idle":"2023-12-02T14:41:52.603893Z","shell.execute_reply":"2023-12-02T14:41:52.603189Z","shell.execute_reply.started":"2023-12-02T14:41:52.587989Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["class YoubikeDataset(Dataset):\n","    def __init__(self, data, dataType):\n","        super(YoubikeDataset, self).__init__()\n","        # [month, date, weekday, hr, min, lat, lng, act, ratio, sbi, tot, title, act_title]\n","        # [month, day ,weekday ,hr ,min ,lat ,lng ,act ,tot ,title ]\n","        self.data = data\n","        self.datasize = len(self.data)\n","        self.type = dataType\n","\n","    def __getitem__(self, idx):\n","        if self.type == \"train\" or self.type == \"val\":\n","            features = self.data[idx][:-112]\n","            labels = self.data[idx][-112:]\n","            return torch.FloatTensor(features), torch.FloatTensor(labels)\n","        elif self.type == \"test\":\n","            features = self.data[idx][:-224]\n","            outputInfo = self.data[idx][-224:]\n","            return torch.FloatTensor(features), outputInfo\n","        else:\n","            raise NotImplementedError\n","            \n","    def __len__(self):\n","        return self.datasize"]},{"cell_type":"markdown","metadata":{"_cell_guid":"420e9d0b-95a7-4047-9656-b874e3217306","_uuid":"4eac3393-99bb-4326-9c09-16cd1f2dac43","trusted":true},"source":["## My Model(s)"]},{"cell_type":"markdown","metadata":{"_cell_guid":"6104fbaa-4599-453a-8a89-9ee3b4be7b12","_uuid":"9794c4b8-a152-4f8b-a702-3af6ab50ce97","trusted":true},"source":["### DNN model"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a3cfbb1c-1ee7-4fff-972c-cf650e731c0b","_uuid":"1f21a170-1062-4c0b-98ba-62f9d15f538f","collapsed":false,"execution":{"iopub.execute_input":"2023-12-02T14:41:52.605218Z","iopub.status.busy":"2023-12-02T14:41:52.604935Z","iopub.status.idle":"2023-12-02T14:41:52.625607Z","shell.execute_reply":"2023-12-02T14:41:52.624747Z","shell.execute_reply.started":"2023-12-02T14:41:52.605181Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["class My_Model(nn.Module):\n","    def __init__(self, input_dim, output_dim):\n","        super(My_Model, self).__init__()\n","        # TODO: modify model's structure, be aware of dimensions. \n","        self.layers = nn.Sequential(\n","            nn.Linear(input_dim, input_dim),\n","            nn.Dropout(p=0.1),\n","            nn.ReLU(),\n","            nn.Linear(input_dim, 2*input_dim),\n","            nn.Dropout(p=0.1),\n","            nn.ReLU(),\n","            nn.Linear(2*input_dim, 4*input_dim),\n","            nn.Dropout(p=0.1),\n","            nn.ReLU(),\n","            nn.Linear(4*input_dim, 8*input_dim),\n","            nn.Dropout(p=0.1),\n","            nn.ReLU(),\n","            nn.Linear(8*input_dim, 8*input_dim),\n","            nn.Dropout(p=0.1),\n","            nn.ReLU(),\n","            nn.Linear(8*input_dim, 4*input_dim),\n","            nn.Dropout(p=0.1),\n","            nn.ReLU(), \n","            nn.Linear(4*input_dim, 2*input_dim),\n","            nn.Dropout(p=0.1),\n","            nn.ReLU(),\n","            nn.Linear(2*input_dim, input_dim),\n","            nn.Dropout(p=0.1),\n","            nn.ReLU(),\n","            nn.Linear(input_dim, output_dim*2),\n","            nn.Dropout(p=0.1),\n","            nn.ReLU(),\n","            nn.Linear(output_dim*2, output_dim),\n","#             nn.Dropout(p=0.1),\n","            nn.Sigmoid(),\n","#             nn.Linear(input_dim, 4),\n","#             nn.Sigmoid(),\n","#             nn.Linear(4, 2),\n","#             nn.Sigmoid(),\n","#             nn.Linear(2, 1),\n","#             nn.Sigmoid(),\n","#             nn.Linear(input_dim, 1),\n","#             nn.Sigmoid(),\n","        )\n","\n","    def forward(self, x):\n","        x = self.layers(x)\n","        return x"]},{"cell_type":"markdown","metadata":{"_cell_guid":"c93605b9-e61a-4406-ac07-9af124a892ce","_uuid":"67437db6-a6a8-436e-b180-f5a7207bc051","trusted":true},"source":["## My Loss Function"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8a261f5c-9b4f-4c11-b5c6-544de13f797c","_uuid":"347621a1-bfc7-4cef-a557-2fb42fd2b279","collapsed":false,"execution":{"iopub.execute_input":"2023-12-02T14:41:52.626951Z","iopub.status.busy":"2023-12-02T14:41:52.626703Z","iopub.status.idle":"2023-12-02T14:41:52.643553Z","shell.execute_reply":"2023-12-02T14:41:52.642723Z","shell.execute_reply.started":"2023-12-02T14:41:52.626930Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def getLoss(pred, label):\n","    loss = torch.mean(torch.square(pred-label))\n","#     print(f\"loss = {loss}\")\n","    return loss"]},{"cell_type":"markdown","metadata":{"_cell_guid":"475a5f4e-e4ab-46d7-94f3-75e1159a9379","_uuid":"c2c5b894-c457-4860-b5e1-05f0b7fa18fc","trusted":true},"source":["## Training function"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"06d3556a-ad61-4ccf-a9c7-62ab152e90df","_uuid":"ca28bea5-8dc0-483d-8571-c46ecac15d8d","collapsed":false,"execution":{"iopub.execute_input":"2023-12-02T14:41:52.644985Z","iopub.status.busy":"2023-12-02T14:41:52.644729Z","iopub.status.idle":"2023-12-02T14:41:52.660110Z","shell.execute_reply":"2023-12-02T14:41:52.659153Z","shell.execute_reply.started":"2023-12-02T14:41:52.644962Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def train(model, config, train_loader, valid_loader, device):\n","#     criterion = nn.MSELoss(reduction='mean') # Define your loss function, do not modify this.\n","    # criterion = nn.CrossEntropyLoss()\n","#     optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay']) \n","    optimizer = torch.optim.SGD(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay']) \n","    scheduler = CosineAnnealingWarmRestarts(optimizer,T_0=1,T_mult=2)\n","    if not os.path.isdir(config[\"save_dir\"]):\n","        os.mkdir(config[\"save_dir\"]) # Create directory of saving models.\n","\n","    n_epochs, best_loss, step, early_stop_count = config['epochs'], math.inf, 0, 0\n","\n","    for epoch in range(n_epochs):\n","        model.train() # Set your model to train mode.\n","        loss_record = []\n","        print(scheduler.get_last_lr())\n","\n","        # tqdm is a package to visualize your training progress.\n","        train_pbar = tqdm(train_loader, position=0, leave=True)\n","        final_y, final_pred = None, None\n","        for x, y in train_pbar:\n","            optimizer.zero_grad()               # Set gradient to zero.\n","            x, y = x.to(device), y.to(device)   # Move your data to device. \n","            pred = model(x) \n","            \n","            loss = getLoss(pred, y)\n","            loss.backward()                     # Compute gradient(backpropagation).\n","            optimizer.step()                    # Update parameters.\n","            step += 1\n","            loss_record.append(loss.detach().item())\n","            \n","            # Display current epoch number and loss on tqdm progress bar.\n","            train_pbar.set_description(f'Epoch [{epoch+1}/{n_epochs}]')\n","            train_pbar.set_postfix({'loss': loss.detach().item()})\n","            final_y = y\n","            final_pred = pred\n","\n","        scheduler.step()\n","        mean_train_loss = sum(loss_record)/len(loss_record)\n","        print(final_y)\n","        print(final_pred)\n","\n","        model.eval() # Set your model to evaluation mode.\n","        loss_record = []\n","        for x, y in valid_loader:\n","            x, y = x.to(device), y.to(device)\n","            with torch.no_grad():\n","                pred = model(x)\n","                loss = getLoss(pred, y)\n","\n","            loss_record.append(loss.item())\n","            \n","        mean_valid_loss = sum(loss_record)/len(loss_record)\n","        print(f'Epoch [{epoch+1}/{n_epochs}]: Train loss: {mean_train_loss:.4f}, Valid loss: {mean_valid_loss:.4f}')\n","        # writer.add_scalar('Loss/valid', mean_valid_loss, step)\n","\n","        if mean_valid_loss < best_loss:\n","            best_loss = mean_valid_loss\n","            torch.save(model.state_dict(), config['save_dir'] + config['model_name']) # Save your best model\n","            print('Saving model with loss {:.4f}...'.format(best_loss))\n","            early_stop_count = 0\n","        else: \n","            early_stop_count += 1\n","\n","        if early_stop_count >= config['early_stop']:\n","            print('\\nModel is not improving, so we halt the training session.')\n","            print('best loss {:.4f}...'.format(best_loss))\n","            return"]},{"cell_type":"markdown","metadata":{"_cell_guid":"1560181e-e304-48bf-bdb8-03366dc0b154","_uuid":"df41ce06-1683-434e-b250-6969e3bf7230","trusted":true},"source":["## Predict function"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"60941160-9ba4-47e7-aad8-f227f2359b73","_uuid":"fcd12733-6b47-43a7-8b69-90d75b072dd6","collapsed":false,"execution":{"iopub.execute_input":"2023-12-02T15:14:13.112113Z","iopub.status.busy":"2023-12-02T15:14:13.111715Z","iopub.status.idle":"2023-12-02T15:14:13.122590Z","shell.execute_reply":"2023-12-02T15:14:13.121655Z","shell.execute_reply.started":"2023-12-02T15:14:13.112083Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def predict(test_loader, model, device):\n","    model.eval() # Set your model to evaluation mode.\n","    preds = []\n","    tots = []\n","    titles = []\n","    for x, tmp in tqdm(test_loader):\n","        x = x.to(device)   \n","        infos = []\n","        for i in range(len(tmp[0])):\n","            lst = [tmp[x][i] for x in range(len(tmp)) ]\n","            infos = infos + lst\n","        for idx, info in enumerate(infos):\n","            if idx % 2 == 0:\n","                tots.append(info)\n","            else:\n","                titles.append(info)\n","        with torch.no_grad():                   \n","            pred = model(x)                     \n","            preds.append(pred.detach().cpu())\n","            \n","    preds = list(np.concatenate(preds).flat)\n","    print(len(preds), len(tots), len(titles))\n","    assert len(preds) == len(tots)\n","    assert len(tots) == len(titles)\n","    prediction = [['id','sbi']]\n","    for (pred, tot, title) in zip(preds, tots, titles):\n","        prediction.append([title, pred*tot.item()])\n","    \n","    with open('prediction.csv', 'w', newline='') as file:\n","    # Step 4: Using csv.writer to write the list to the CSV file\n","        writer = csv.writer(file)\n","        writer.writerows(prediction) # Use writerows for nested list\n","    \n","    return"]},{"cell_type":"markdown","metadata":{"_cell_guid":"0c055bfc-067a-4b4c-9b11-a314cdb3a32d","_uuid":"77ee2261-8391-4a2a-a593-6a69d5114ee0","trusted":true},"source":["# Hyperparameters"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5b8c80e4-d544-41bc-a37b-898f74bdb50f","_uuid":"f7b481f8-bdb2-4eff-98b4-30aa684bddee","collapsed":false,"execution":{"iopub.execute_input":"2023-12-02T15:26:33.911733Z","iopub.status.busy":"2023-12-02T15:26:33.911350Z","iopub.status.idle":"2023-12-02T15:26:33.917697Z","shell.execute_reply":"2023-12-02T15:26:33.916786Z","shell.execute_reply.started":"2023-12-02T15:26:33.911708Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["config = {\n","    \"batch_size\": 2,\n","#     \"data_filepath\": 'dataset_csv/',\n","    \"data_filepath\": '/kaggle/input/dataset-1201-new/dataset_w_csv/',\n","#     \"inference_filepath\": '/kaggle/input/inference-1204/inference_csv/',\n","    \"inference_filepath\": '/kaggle/input/inference-new-1204/inference_w_csv/',\n","    \"epochs\": 100,\n","    \"learning_rate\": 2.5e-3,\n","#     \"weight_decay\": 5e-4,\n","    \"weight_decay\": 0,\n","    \"save_dir\": \"./models/\",\n","    \"model_name\": \"1201-DNN.ckpt\",\n","    \"checkpoint\": \"/kaggle/input/300-ckpt/1201-DNN.ckpt\",\n","    \"useCheckpoint\": True,\n","    \"early_stop\":100,\n","    \"seeds\": 10901039\n","}\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"markdown","metadata":{"_cell_guid":"719398f7-831c-432c-8a32-54b13ca2b940","_uuid":"cad4ef4f-ba16-4919-9a9b-7e29ac6ab21e","trusted":true},"source":["## Load Datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"724cb34d-0f6a-4715-b1ae-a13acd9e1b32","_uuid":"1630ec01-2dcb-4730-8b86-25c78a1032fb","collapsed":false,"execution":{"iopub.execute_input":"2023-12-02T14:41:52.766762Z","iopub.status.busy":"2023-12-02T14:41:52.766472Z","iopub.status.idle":"2023-12-02T14:41:57.223171Z","shell.execute_reply":"2023-12-02T14:41:57.222298Z","shell.execute_reply.started":"2023-12-02T14:41:52.766737Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["same_seeds(config[\"seeds\"])\n","train_data, valid_data, test_data = readDataset(config['data_filepath'], config['inference_filepath'])\n","print(f'train_data_size: {len(train_data)}')\n","print(f'valid_data_size: {len(valid_data)}')\n","print(f'test_data_size : {len(test_data)}')\n","train_dataset, valid_dataset, test_dataset = YoubikeDataset(train_data, \"train\"), YoubikeDataset(valid_data, \"val\"), YoubikeDataset(test_data, \"test\")\n","train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\n","valid_loader = DataLoader(valid_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\n","test_loader  = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False, pin_memory=True)"]},{"cell_type":"markdown","metadata":{},"source":["## Load Checkpoint"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-02T15:21:12.109510Z","iopub.status.busy":"2023-12-02T15:21:12.109094Z","iopub.status.idle":"2023-12-02T15:21:12.939720Z","shell.execute_reply":"2023-12-02T15:21:12.938741Z","shell.execute_reply.started":"2023-12-02T15:21:12.109463Z"},"trusted":true},"outputs":[],"source":["model = My_Model(input_dim=len(train_data[0])-112, output_dim=112).to(device) # put your model and data on the same computation device.\n","if config['useCheckpoint']:\n","    model.load_state_dict(torch.load(config['checkpoint']))\n","    \n","print(model)"]},{"cell_type":"markdown","metadata":{"_cell_guid":"d6504785-d164-417e-9945-c223660f0b76","_uuid":"a67e9f5a-9cea-4fa1-9265-edd6620f1ba4","trusted":true},"source":["## Start Training"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"87385bfc-3634-4f6c-8580-0fa459f07111","_uuid":"d80900d2-5ac2-4b39-ba7e-f4ae8d404e73","execution":{"iopub.execute_input":"2023-12-02T15:26:38.989347Z","iopub.status.busy":"2023-12-02T15:26:38.988643Z"},"trusted":true},"outputs":[],"source":["train(model, config, train_loader, valid_loader, device)"]},{"cell_type":"markdown","metadata":{"_cell_guid":"87c72eb7-4c92-4558-967b-10c3d39418b4","_uuid":"6005ee34-f764-4696-9167-740dedd54fad","trusted":true},"source":["## Inference"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cf8b912f-284c-4b20-bfa7-5e216b4e93f6","_uuid":"32c5adff-6cef-4bf7-93f1-6092c5307665","execution":{"iopub.execute_input":"2023-12-02T15:21:18.634584Z","iopub.status.busy":"2023-12-02T15:21:18.633450Z","iopub.status.idle":"2023-12-02T15:21:21.358415Z","shell.execute_reply":"2023-12-02T15:21:21.357634Z","shell.execute_reply.started":"2023-12-02T15:21:18.634538Z"},"trusted":true},"outputs":[],"source":["predict(test_loader, model, device)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4087683,"sourceId":7093039,"sourceType":"datasetVersion"},{"datasetId":4087799,"sourceId":7093178,"sourceType":"datasetVersion"},{"datasetId":4092622,"sourceId":7099924,"sourceType":"datasetVersion"},{"datasetId":4095144,"sourceId":7103711,"sourceType":"datasetVersion"},{"datasetId":4095417,"sourceId":7104130,"sourceType":"datasetVersion"},{"datasetId":4096906,"sourceId":7106305,"sourceType":"datasetVersion"}],"dockerImageVersionId":30587,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":4}
